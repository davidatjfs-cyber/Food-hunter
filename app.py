import streamlit as st
import datetime
from langchain_openai import ChatOpenAI
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
# å¼•å…¥è¯­éŸ³è¯†åˆ«ç»„ä»¶
from streamlit_speech_to_text import speech_to_text

# --- 1. é¡µé¢é…ç½® ---
st.set_page_config(
    page_title="FoodHunter Voice",
    page_icon="ğŸ™ï¸",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# æ³¨å…¥ CSS (ä¼˜åŒ–æŒ‰é’®å’Œé“¾æ¥æ ·å¼)
st.markdown("""
<style>
    .stChatInput {position: fixed; bottom: 0; padding-bottom: 15px; background: white; z-index: 999;}
    .block-container {padding-top: 2rem; padding-bottom: 12rem;} /* ç•™å‡ºåº•éƒ¨ç©ºé—´ç»™è¯­éŸ³æŒ‰é’® */
    h1 {color: #1A1A1A;}
    
    /* æŠ¥å‘Šå¡ç‰‡ */
    .report-card {
        background-color: #fff;
        padding: 25px;
        border-radius: 15px;
        border: 1px solid #e0e0e0;
        border-left: 6px solid #CCA352;
        margin-top: 20px;
        box-shadow: 0 5px 15px rgba(0,0,0,0.05);
    }
    .dish-title {
        font-size: 1.3rem;
        font-weight: bold;
        margin-bottom: 10px;
    }
    /* å¼ºåˆ¶é“¾æ¥æ ·å¼ï¼Œç¡®ä¿çœ‹èµ·æ¥åƒå¯ä»¥ç‚¹çš„ */
    .dish-title a {
        color: #0066cc !important;
        text-decoration: underline !important;
        cursor: pointer;
    }
    .fusion-badge {
        background-color: #1A1A1A;
        color: #CCA352;
        padding: 4px 10px;
        border-radius: 4px;
        font-size: 0.7rem;
        margin-left: 8px;
        vertical-align: middle;
    }
</style>
""", unsafe_allow_html=True)

# --- 2. å¯†é’¥ç®¡ç† ---
def get_api_key(key_name):
    if key_name in st.secrets:
        return st.secrets[key_name]
    return None

deepseek_key = get_api_key("DEEPSEEK_API_KEY")
tavily_key = get_api_key("TAVILY_API_KEY")

if "messages" not in st.session_state:
    st.session_state.messages = []

# --- 3. ä¾§è¾¹æ  ---
with st.sidebar:
    st.title("âš™ï¸ è®¾ç½®")
    with st.expander("ğŸ”‘ API Key é…ç½®"):
        if not deepseek_key:
            deepseek_key = st.text_input("DeepSeek Key", type="password")
        if not tavily_key:
            tavily_key = st.text_input("Tavily Key", type="password")
    
    if st.button("ğŸ—‘ï¸ æ¸…ç©ºèŠå¤©è®°å½•"):
        st.session_state.messages = []
        st.rerun()

# --- 4. æ ‡é¢˜ ---
st.title("ğŸ‘¨â€ğŸ³ è¡Œæ”¿æ€»å¨ (è¯­éŸ³ç‰ˆ)")
st.caption("v11.0: ç‚¹å‡»ä¸‹æ–¹éº¦å…‹é£å³å¯è¯´è¯ â€¢ è“è‰²é“¾æ¥ç‚¹å‡»ç›´è¾¾å›¾ç‰‡")

# --- 5. æ ¸å¿ƒ Prompt (å¼ºè°ƒé“¾æ¥æ ¼å¼) ---
base_url = "https://api.deepseek.com"
model_name = "deepseek-chat"

FUSION_PROMPT = """
ä½ æ˜¯ä¸€åç²¾é€š**ã€ä¸­è¥¿èåˆèœ (Fusion Cuisine)ã€‘**çš„è¡Œæ”¿æ€»å¨ã€‚
ç”¨æˆ·éœ€æ±‚ï¼š"{user_input}"
æƒ…æŠ¥ï¼š"{evidence}"

è¯·æä¾› **3ä¸ª** ä¸­è¥¿ç»“åˆçš„ç ”å‘æ–¹æ¡ˆã€‚

âš ï¸ **å¿…é¡»ä¸¥æ ¼éµå®ˆçš„é“¾æ¥æ ¼å¼ï¼š**
æåˆ°å…·ä½“çš„ã€èœåã€‘æ—¶ï¼Œå¿…é¡»ä½¿ç”¨ Markdown é“¾æ¥æ ¼å¼ï¼Œä¸”é“¾æ¥åœ°å€å¿…é¡»æ˜¯ Google å›¾ç‰‡æœç´¢ã€‚
æ ¼å¼ï¼š`[èœå](https://www.google.com/search?q=èœå&tbm=isch)`
*(æ³¨æ„ï¼šq=åé¢ç›´æ¥è·Ÿèœå)*

æŠ¥å‘Šç»“æ„ï¼š
<div class="report-card">
    <div class="dish-title">
        1. [èœå](https://www.google.com/search?q=èœå&tbm=isch) 
        <span class="fusion-badge">Fusion Idea</span>
    </div>
    <p><strong>ğŸ’¡ èåˆåˆ›æ„ï¼š</strong> (è§£é‡Šä¸­è¥¿ç»“åˆç‚¹)</p>
    <p><strong>ğŸ‘¨â€ğŸ³ æ ¸å¿ƒåšæ³•ï¼š</strong> (ç®€è¿°é£Ÿæä¸æŠ€æ³•)</p>
</div>

<div class="report-card">
    <div class="dish-title">
        2. [èœå](https://www.google.com/search?q=èœå&tbm=isch) 
        <span class="fusion-badge">Fusion Idea</span>
    </div>
    <p><strong>ğŸ’¡ èåˆåˆ›æ„ï¼š</strong> ...</p>
    <p><strong>ğŸ‘¨â€ğŸ³ æ ¸å¿ƒåšæ³•ï¼š</strong> ...</p>
</div>

<div class="report-card">
    <div class="dish-title">
        3. [èœå](https://www.google.com/search?q=èœå&tbm=isch) 
        <span class="fusion-badge">Fusion Idea</span>
    </div>
    <p><strong>ğŸ’¡ èåˆåˆ›æ„ï¼š</strong> ...</p>
    <p><strong>ğŸ‘¨â€ğŸ³ æ ¸å¿ƒåšæ³•ï¼š</strong> ...</p>
</div>
"""

# --- 6. ä¸»ç¨‹åº ---

# æ˜¾ç¤ºå†å²æ¶ˆæ¯
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        if msg["role"] == "assistant":
            st.markdown(msg["content"], unsafe_allow_html=True)
        else:
            st.markdown(msg["content"])

# --- è¯­éŸ³è¾“å…¥æ¨¡å— (æ”¾ç½®åœ¨é¡µé¢åº•éƒ¨) ---
# åˆ›å»ºä¸¤åˆ—ï¼Œå·¦è¾¹æ”¾æ–‡æœ¬è¾“å…¥æ¡†(åŸç”Ÿ)ï¼Œå³è¾¹æ”¾éº¦å…‹é£(æ’ä»¶)
# æ³¨æ„ï¼šç”±äºStreamlité™åˆ¶ï¼Œæˆ‘ä»¬æŠŠéº¦å…‹é£æ”¾åœ¨è¾“å…¥æ¡†ä¸Šæ–¹ä¸€ç‚¹

st.markdown("---")
c1, c2 = st.columns([8, 1])
with c1:
    # è¿™é‡Œçš„æ–‡æœ¬æç¤º
    st.caption("ğŸ‘‡ ç‚¹å‡»ä¸‹æ–¹éº¦å…‹é£è¯´è¯ï¼Œæˆ–åœ¨åº•éƒ¨è¾“å…¥æ¡†æ‰“å­—")

with c2:
    # è¯­éŸ³æŒ‰é’®ç»„ä»¶
    voice_text = speech_to_text(
        language='zh-CN',  # è®¾ç½®ä¸ºä¸­æ–‡
        start_prompt="ğŸ™ï¸",
        stop_prompt="â¹ï¸",
        just_once=True,
        key='STT'
    )

# å¤„ç†è¾“å…¥é€»è¾‘
final_input = None

# æƒ…å†µ1ï¼šç”¨æˆ·ç”¨äº†è¯­éŸ³
if voice_text:
    final_input = voice_text
    # è¯­éŸ³è¾“å…¥åï¼Œä¸ºäº†é˜²æ­¢é‡å¤æäº¤ï¼Œæˆ‘ä»¬å¯ä»¥æ˜¾ç¤ºå‡ºæ¥
    st.toast(f"ğŸ¤ å¬åˆ°ï¼š{voice_text}")

# æƒ…å†µ2ï¼šç”¨æˆ·ç”¨äº†é”®ç›˜æ‰“å­— (chat_input)
text_input = st.chat_input("è¾“å…¥ç ”å‘éœ€æ±‚...")
if text_input:
    final_input = text_input

# --- æ‰§è¡Œé€»è¾‘ ---
if final_input:
    # å­˜å…¥å†å²
    st.session_state.messages.append({"role": "user", "content": final_input})
    with st.chat_message("user"):
        st.markdown(final_input)

    if not deepseek_key or not tavily_key:
        st.error("âŒ æœªæ£€æµ‹åˆ° API Key")
        st.stop()

    with st.chat_message("assistant"):
        placeholder = st.empty()
        try:
            with st.spinner("ğŸ‘¨â€ğŸ³ æ­£åœ¨å¬å–æŒ‡ä»¤å¹¶ç ”å‘..."):
                # æœç´¢
                search_query = f"{final_input} ä¸­è¥¿èåˆèœ åˆ›æ„åšæ³• é£Ÿææ­é…"
                search = TavilySearchResults(tavily_api_key=tavily_key, max_results=5)
                evidence = search.invoke(search_query)
                
                # æ¨ç†
                llm = ChatOpenAI(base_url=base_url, api_key=deepseek_key, model=model_name, temperature=0.7)
                
                chain = ChatPromptTemplate.from_messages([
                    ("system", FUSION_PROMPT),
                    ("user", "") 
                ]) | llm | StrOutputParser()
                
                response = chain.invoke({
                    "user_input": final_input, 
                    "evidence": evidence
                })

                placeholder.markdown(response, unsafe_allow_html=True)
                st.session_state.messages.append({"role": "assistant", "content": response})

        except Exception as e:
            st.error(f"è¿è¡Œå‡ºé”™: {e}")
