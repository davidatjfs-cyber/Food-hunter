import streamlit as st
import datetime
from langchain_openai import ChatOpenAI
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

# --- 1. é¡µé¢é…ç½® ---
st.set_page_config(
    page_title="FoodHunter Pro",
    page_icon="ğŸ¦",
    layout="wide",
    initial_sidebar_state="collapsed"
)

st.markdown("""
<style>
    .stChatInput {position: fixed; bottom: 0; padding-bottom: 15px; background: white; z-index: 999;}
    .block-container {padding-top: 2rem; padding-bottom: 10rem;} 
    h1 {color: #D32F2F;}
    .report-card {
        background-color: #f8f9fa;
        padding: 20px;
        border-radius: 12px;
        border-left: 5px solid #D32F2F;
        margin-top: 10px;
    }
</style>
""", unsafe_allow_html=True)

# --- 2. å¯†é’¥ç®¡ç† ---
def get_api_key(key_name):
    if key_name in st.secrets:
        return st.secrets[key_name]
    return None

deepseek_key = get_api_key("DEEPSEEK_API_KEY")
tavily_key = get_api_key("TAVILY_API_KEY")

# åˆå§‹åŒ– Session
if "messages" not in st.session_state:
    st.session_state.messages = []

# --- 3. ä¾§è¾¹æ  ---
with st.sidebar:
    st.title("âš™ï¸ è®¾ç½®")
    with st.expander("ğŸ”‘ API Key é…ç½®"):
        if not deepseek_key:
            deepseek_key = st.text_input("DeepSeek Key", type="password")
        if not tavily_key:
            tavily_key = st.text_input("Tavily Key", type="password")
    
    if st.button("ğŸ—‘ï¸ æ¸…ç©ºèŠå¤©è®°å½•"):
        st.session_state.messages = []
        st.rerun()

# --- 4. æ ‡é¢˜ ---
st.title("ğŸ¦ é¤é¥®æƒ…æŠ¥å®˜ (æ™ºèƒ½æœç´¢ç‰ˆ)")
st.caption("v7.0: è‡ªåŠ¨ä¼˜åŒ–æœç´¢è¯ï¼Œè§£å†³ç­”éæ‰€é—®")

def handle_quick_action(prompt_text):
    st.session_state.messages.append({"role": "user", "content": prompt_text})
    st.session_state.trigger_run = True

if len(st.session_state.messages) == 0:
    st.markdown("### ğŸ”¥ è¯•ä¸€è¯•")
    c1, c2 = st.columns(2)
    with c1:
        if st.button("ğŸ² æœ¬æœˆçˆ†æ¬¾æ‹†è§£"):
            handle_quick_action("å¸®æˆ‘æœä¸€ä¸‹æœ€è¿‘ä¸€ä¸ªæœˆä¸Šæµ·é¤é¥®å¸‚åœºæœ€ç«çš„çˆ†æ¬¾å•å“æ˜¯ä»€ä¹ˆï¼Ÿ")
            st.rerun()
    with c2:
        if st.button("ğŸ‘€ ç«å¯¹å·®è¯„åˆ†æ"):
            handle_quick_action("å¸®æˆ‘æœä¸€ä¸‹ä¸Šæµ·å¤§å®ä¹…å…‰é™„è¿‘çš„ç²¤èœé¦†ï¼Œçœ‹çœ‹é¡¾å®¢å·®è¯„ä¸»è¦é›†ä¸­åœ¨å“ªï¼Ÿ")
            st.rerun()

# --- 5. æ ¸å¿ƒé€»è¾‘ï¼šä¸¤æ­¥èµ° (å…ˆç”Ÿæˆæœç´¢è¯ -> å†ç”ŸæˆæŠ¥å‘Š) ---
base_url = "https://api.deepseek.com"
model_name = "deepseek-chat"

# A. æœç´¢è¯ä¼˜åŒ–ä¸“å®¶ Agent
QUERY_GEN_PROMPT = """
ä½ æ˜¯ä¸€ä¸ªGoogleæœç´¢ä¸“å®¶ã€‚
ç”¨æˆ·çš„åŸå§‹é—®é¢˜æ˜¯ï¼š"{user_input}"
ä»Šå¤©æ˜¯ï¼š{current_date}

è¯·å°†è¿™ä¸ªé—®é¢˜è½¬åŒ–ä¸º**ä¸€ä¸ª**æœ€é€‚åˆåœ¨æœç´¢å¼•æ“è¾“å…¥çš„å…³é”®è¯ã€‚
ç›®æ ‡ï¼šæ‰¾åˆ°æœ€æ–°çš„ã€çœŸå®çš„æ¶ˆè´¹è€…è¯„ä»·æˆ–é¤é¥®æ•°æ®ã€‚
æŠ€å·§ï¼š
1. å»æ‰è¯­æ°”è¯ã€‚
2. åŠ ä¸Šå…·ä½“çš„åœ°åŸŸï¼ˆå¦‚æœç”¨æˆ·æ²¡è¯´ï¼Œé»˜è®¤å‡è®¾æ˜¯ä¸Šæµ·ï¼‰ã€‚
3. åŠ ä¸Š"å¤§ä¼—ç‚¹è¯„"ã€"å°çº¢ä¹¦"ã€"æ¨è"ã€"é¿å‘"ç­‰è¯ã€‚

**åªè¾“å‡ºä¼˜åŒ–åçš„æœç´¢è¯ï¼Œä¸è¦æœ‰ä»»ä½•å…¶ä»–åºŸè¯ã€‚**
"""

# B. æŠ¥å‘Šç”Ÿæˆä¸“å®¶ Agent
REPORT_PROMPT = """
ä½ æ˜¯ä¸€åé¤é¥®æ•°æ®åˆ†æå¸ˆã€‚
è¯·åŸºäºä»¥ä¸‹çš„ã€æœç´¢ç»“æœã€‘ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ï¼š"{user_input}"

âš ï¸ **å›ç­”åŸåˆ™ï¼š**
1. **ç›´æ¥å›ç­”ï¼š** ä¸è¦åœ¨é‚£ç»•å¼¯å­ï¼Œç›´æ¥ç»™å‡ºç»“è®ºã€‚
2. **åŸºäºè¯æ®ï¼š** æœç´¢ç»“æœé‡Œè¯´äº†ä»€ä¹ˆå°±è¯´ä»€ä¹ˆï¼Œæ²¡è¯´å°±è¯´æ²¡æŸ¥åˆ°ã€‚
3. **è§†è§‰é“¾æ¥ï¼š** ä»…ç»™ã€æ ¸å¿ƒèœåã€‘åŠ é“¾æ¥ï¼š[èœå](https://www.google.com/search?tbm=isch&q=èœå)ã€‚

æŠ¥å‘Šç»“æ„ï¼š
<div class="report-card">
<h3>ğŸ“Š æ ¸å¿ƒç»“è®º</h3>
(ç›´çƒå›ç­”ç”¨æˆ·çš„é—®é¢˜)

<h4>1. ğŸ•µï¸â€â™‚ï¸ è¯¦ç»†æƒ…æŠ¥</h4>
(åˆ—å‡ºå…·ä½“çš„èœå“ã€è¯„ä»·æˆ–æ•°æ®)

<h4>2. ğŸ’¡ å»ºè®®</h4>
(ç®€çŸ­å»ºè®®)
</div>

---
**å‚è€ƒèµ„æ–™ï¼š** {evidence}
"""

# --- 6. ä¸»ç¨‹åº ---
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        if msg["role"] == "assistant":
            st.markdown(msg["content"], unsafe_allow_html=True)
        else:
            st.markdown(msg["content"])

user_input = st.chat_input("è¾“å…¥æ‚¨çš„é—®é¢˜...")

if user_input or st.session_state.get("trigger_run", False):
    if st.session_state.get("trigger_run", False):
        current_prompt = st.session_state.messages[-1]["content"]
        st.session_state.trigger_run = False
    else:
        current_prompt = user_input
        st.session_state.messages.append({"role": "user", "content": current_prompt})
        with st.chat_message("user"):
            st.markdown(current_prompt)

    if not deepseek_key or not tavily_key:
        st.error("âŒ æœªæ£€æµ‹åˆ° API Key")
        st.stop()

    with st.chat_message("assistant"):
        placeholder = st.empty()
        try:
            now = datetime.datetime.now()
            llm = ChatOpenAI(base_url=base_url, api_key=deepseek_key, model=model_name, temperature=0.5)

            # --- ç¬¬ä¸€æ­¥ï¼šæ™ºèƒ½ç”Ÿæˆæœç´¢è¯ ---
            with st.status("ğŸ§  æ­£åœ¨æ€è€ƒæœ€ä½³æœç´¢ç­–ç•¥...", expanded=True) as status:
                gen_chain = ChatPromptTemplate.from_template(QUERY_GEN_PROMPT) | llm | StrOutputParser()
                optimized_query = gen_chain.invoke({
                    "user_input": current_prompt,
                    "current_date": now.strftime("%Y-%m-%d")
                })
                # æ¸…ç†ä¸€ä¸‹ç”Ÿæˆçš„è¯ï¼ˆå»æ‰å¯èƒ½çš„å¼•å·ï¼‰
                optimized_query = optimized_query.replace('"', '').strip()
                
                status.write(f"ğŸ” åŸå§‹é—®é¢˜ï¼š{current_prompt}")
                status.write(f"âœ¨ **ä¼˜åŒ–åå»æœï¼š** `{optimized_query}`")
                
                # --- ç¬¬äºŒæ­¥ï¼šæ‰§è¡Œæœç´¢ ---
                status.write("æ­£åœ¨å…¨ç½‘æ£€ç´¢...")
                search = TavilySearchResults(tavily_api_key=tavily_key, max_results=5)
                evidence = search.invoke(optimized_query)
                status.write(f"âœ… æ‰¾åˆ° {len(evidence)} æ¡ç›¸å…³æƒ…æŠ¥")
                status.update(label="âœ… æƒ…æŠ¥æ”¶é›†å®Œæ¯•", state="complete", expanded=False)

            # --- ç¬¬ä¸‰æ­¥ï¼šç”Ÿæˆå›ç­” ---
            final_chain = ChatPromptTemplate.from_template(REPORT_PROMPT) | llm | StrOutputParser()
            response = final_chain.invoke({
                "user_input": current_prompt,
                "evidence": evidence
            })

            placeholder.markdown(response, unsafe_allow_html=True)
            st.session_state.messages.append({"role": "assistant", "content": response})

        except Exception as e:
            st.error(f"è¿è¡Œå‡ºé”™: {e}")
